version: "3.7"

services:
  # ===============================
  # MinIO : stockage S3 compatible Iceberg
  # ===============================
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    container_name: minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}  # Ne pas oublier de définir dans .env ou shell
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: ${MINIO_REGION}          # Iceberg et Nessie utilisent cette région
      MINIO_DOMAIN: minio
    ports:
      - "9000:9000"  # Port API S3
      - "9001:9001"  # Port console web
    networks:
      iceberg_net:
        aliases:
          - lakehouse.minio  # Alias réseau interne pour Spark / Nessie
    volumes:
      - ./minio-data:/data  # Persistance des données MinIO
    # Conseil : pour tester la configuration S3, tu peux te connecter à la console web : http://localhost:9001

  # ===============================
  # Création des buckets nécessaires pour Iceberg
  # ===============================
  create-bucket:
    image: minio/mc:latest
    container_name: create-bucket
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: ${MINIO_REGION}
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until /usr/bin/mc alias set minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}; do sleep 1; done;
      /usr/bin/mc rm -r --force minio/lakehouse;
      /usr/bin/mc mb minio/lakehouse;
      /usr/bin/mc anonymous set public minio/lakehouse;
      /usr/bin/mc rm -r --force minio/raw;
      /usr/bin/mc mb minio/raw;
      /usr/bin/mc anonymous set public minio/raw;
      tail -f /dev/null
      "
    networks:
      iceberg_net:

  # ===============================
  # Spark Master
  # ===============================
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile.spark
    container_name: spark-master
    ports:
      - "7077:7077"  # Port Master
      - "8888:8888"  # Jupyter Notebook
      - "10001:10001" #Thrift Server
      - "8080:8080" # Spark WebUI
      - "4040:4040"
    depends_on:
      - nessie  # Spark doit voir Nessie pour le catalog Iceberg
      - minio   # Spark doit voir MinIO pour S3
    volumes:
      - ./notebooks:/home/iceberg/notebooks/notebooks  # Dossier local pour les notebooks
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
      - SPARK_MODE=master
    networks:
      iceberg_net:
        aliases:
          - spark-master
    command: >
      /bin/bash -c "
        start-master.sh -p 7077 &
        start-history-server.sh &
        start-thriftserver.sh --driver-java-options '-Dderby.system.home=/tmp/derby' &
        notebook  # ← lance Jupyter après les services Spark
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 30s
      retries: 3
    
  spark-worker:
    build:
      context: ./spark
      dockerfile: Dockerfile.spark
    container_name: spark-worker
    depends_on:
      spark-master:
          condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    command: >
      /bin/bash -c "
        echo '⏳ Attente 15s pour que spark-master soit prêt...';
        sleep 15;
        start-worker.sh spark://spark-master:7077 --webui-port 8082;
        tail -f /dev/null
      "
    networks:
      iceberg_net:
        aliases:
          - spark-worker

  # ===============================
  # Nessie : versioning / catalog Iceberg
  # ===============================
  nessie:
    image: ghcr.io/projectnessie/nessie
    container_name: nessie
    environment:
      # Stockage JDBC pour le versioning
      nessie.catalog.default-warehouse: "lakehouse"  # Nom du catalogue par défaut
      # The base location of the warehouse named "lakehouse"
      nessie.catalog.warehouses.lakehouse.location: "s3://lakehouse"
      # Another warehouse named "retail"
      nessie.catalog.warehouses.retail.location: "s3://retail-lakehouse"
      nessie.catalog.service.s3.default-options.region: "us-west-2"
      # For non-AWS S3 you need to specify the endpoint and possibly enable path-style-access
      nessie.catalog.service.s3.default-options.endpoint: ${MINIO_ENDPOINT} 
      nessie.catalog.service.s3.default-options.access-key: urn:nessie-secret:quarkus:my-secrets-default
      my-secrets-default.name.name: ${MINIO_ROOT_USER}
      my-secrets-default.name.secret: ${MINIO_ROOT_PASSWORD}
    ports:
      - "19120:19120"  # API REST Nessie
    depends_on:
      - minio
    networks:
      - iceberg_net
    # Conseil : S'assurer que la base "iceberg" existe dans Postgres, sinon Nessie ne démarre pas


# ===============================
# Réseau interne pour tous les services Iceberg / S3 / Spark
# ===============================
networks:
  iceberg_net:
    driver: bridge
    name: iceberg_net
# ===============================

