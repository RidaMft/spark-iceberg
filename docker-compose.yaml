version: "3.3"

services:
  # ===============================
  # MinIO : stockage S3 compatible Iceberg
  # ===============================
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    container_name: minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}  # Ne pas oublier de définir dans .env ou shell
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: ${MINIO_REGION}          # Iceberg et Nessie utilisent cette région
      MINIO_DOMAIN: minio
    ports:
      - "9000:9000"  # Port API S3
      - "9001:9001"  # Port console web
    networks:
      iceberg_net:
        aliases:
          - lakehouse.minio  # Alias réseau interne pour Spark / Nessie
    volumes:
      - ./minio-data:/data  # Persistance des données MinIO
    # Conseil : pour tester la configuration S3, tu peux te connecter à la console web : http://localhost:9001

  # ===============================
  # Création des buckets nécessaires pour Iceberg
  # ===============================
  create-bucket:
    image: minio/mc:latest
    container_name: create-bucket
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: ${MINIO_REGION}
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until /usr/bin/mc alias set minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}; do sleep 1; done;
      /usr/bin/mc rm -r --force minio/lakehouse;
      /usr/bin/mc mb minio/lakehouse;
      /usr/bin/mc anonymous set public minio/lakehouse;
      /usr/bin/mc rm -r --force minio/raw;
      /usr/bin/mc mb minio/raw;
      /usr/bin/mc anonymous set public minio/raw;
      tail -f /dev/null
      "
    networks:
      iceberg_net:

  # ===============================
  # Spark Master
  # ===============================
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    ports:
      - "9090:9090"  # Spark WebUI
      - "7077:7077"  # Port Master
      - "8888:8888"  # Jupyter Notebook
      - "10001:10001" #Thrift Server
    depends_on:
      - nessie  # Spark doit voir Nessie pour le catalog Iceberg
      - minio   # Spark doit voir MinIO pour S3
    volumes:
      - ./notebooks:/home/iceberg/notebooks/notebooks # Dossier local pour les notebooks
    networks:
      iceberg_net:
        aliases:
          - spark-master

  # ===============================
  # Nessie : versioning / catalog Iceberg
  # ===============================
  nessie:
    image: ghcr.io/projectnessie/nessie
    container_name: nessie
    environment:
      # Stockage JDBC pour le versioning
      nessie.catalog.default-warehouse: "lakehouse"  # Nom du catalogue par défaut
      # The base location of the warehouse named "lakehouse"
      nessie.catalog.warehouses.lakehouse.location: "s3://lakehouse"
      # Another warehouse named "retail"
      nessie.catalog.warehouses.retail.location: "s3://retail-lakehouse"
      nessie.catalog.service.s3.default-options.region: "us-west-2"
      # For non-AWS S3 you need to specify the endpoint and possibly enable path-style-access
      nessie.catalog.service.s3.default-options.endpoint: ${MINIO_ENDPOINT} 
      nessie.catalog.service.s3.default-options.access-key: urn:nessie-secret:quarkus:my-secrets-default
      my-secrets-default.name.name: ${MINIO_ROOT_USER}
      my-secrets-default.name.secret: ${MINIO_ROOT_PASSWORD}
    ports:
      - "19120:19120"  # API REST Nessie
    depends_on:
      - minio
    networks:
      - iceberg_net
    # Conseil : S'assurer que la base "iceberg" existe dans Postgres, sinon Nessie ne démarre pas


# ===============================
# Réseau interne pour tous les services Iceberg / S3 / Spark
# ===============================
networks:
  iceberg_net:

# ===============================

