# ðŸ³ Docker Image : Spark + Iceberg + Jupyter Notebook

Une image Docker autonome intÃ©grant **Apache Spark**, **Apache Iceberg**, et **Jupyter Notebook**, conÃ§ue pour le dÃ©veloppement local ou en environnement cloud (AWS / Azure / GCP). IdÃ©ale pour manipuler des tables Iceberg dans des notebooks Python (PySpark), avec connectivitÃ© native vers S3, ADLS et GCS.

---

## ðŸ§° Technologies intÃ©grÃ©es

| Composant | Version |
|----------|---------|
| **Base** | `python:3.11.4-bullseye` |
| **OpenJDK** | 17 |
| **Spark** | `3.5.7` (Hadoop 3) |
| **Iceberg Runtime** | `1.10.0` (Spark 3.5 + Scala 2.12) |
| **Hadoop-AWS** | `3.3.4` |
| **AWS Java SDK** | `1.12.353` |
| **Bundles Cloud** | `iceberg-aws-bundle`, `iceberg-gcp-bundle`, `iceberg-azure-bundle` (v1.10.0) |
| **Jupyter + PySpark** | Via `spylon-kernel` et `pyspark` |
| **AWS CLI** | v2 (installÃ© globalement) |


---

## ðŸ“¦ FonctionnalitÃ©s

- âœ… ExÃ©cution interactive de notebooks PySpark avec support Iceberg (`CREATE TABLE`, `MERGE INTO`, etc.)
- âœ… Connexion native aux stockages :
  - **AWS S3** via `s3a://`
  - **Azure Data Lake** (ADLS Gen2) via `abfss://`
  - **Google Cloud Storage** via `gs://`
- âœ… PrÃ©chargement des JARs nÃ©cessaires (pas besoin de `--packages`)
- âœ… Interface Jupyter accessible sans token/mot de passe (mode dev uniquement âœ…)
- âœ… Commandes `notebook` / `pyspark-notebook` pour lancer Spark en mode driver notebook
- âœ… Dossiers montables pour notebooks, warehouse locale, etc.

---

## ðŸš€ Utilisation rapide

### Construire lâ€™image

```bash
docker build -t spark-iceberg-jupyter:latest .
```

### Lancer localement

```bash
docker run -it \
  -p 8888:8888 \
  -p 4040:4040 \
  -v $(pwd)/notebooks:/home/iceberg/notebooks \
  -v $(pwd)/warehouse:/home/iceberg/warehouse \
  spark-iceberg-jupyter:latest
```

âž¡ï¸ Ouvrez [http://localhost:8888](http://localhost:8888) dans votre navigateur.

> ðŸ” **SÃ©curitÃ©** : En production, dÃ©sactivez `--NotebookApp.token=''` et ajoutez un mot de passe.

---

## ðŸ“ Structure des dossiers

| Chemin dans le conteneur | Usage |
|--------------------------|-------|
| `/home/iceberg/notebooks` | Dossier par dÃ©faut des notebooks |
| `/home/iceberg/warehouse` | Warehouse locale (peut Ãªtre montÃ©e) |
| `/home/iceberg/localwarehouse` | Alternative pour tests locaux |
| `/home/iceberg/spark-events` | Pour le monitoring Spark UI (Ã  activer via conf) |
| `/opt/spark/conf/spark-defaults.conf` | Fichier de configuration inclus |
| `/opt/spark/jars/` | Tous les JARs Iceberg + Hadoop-AWS prÃ©installÃ©s |

---

## âš™ï¸ Configuration

Le fichier `spark-defaults.conf` est copiÃ© Ã  la construction. Exemple minimal recommandÃ© :

```properties
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
spark.sql.catalog.spark_catalog.type=hive
spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.local.type=hadoop
spark.sql.catalog.local.warehouse=file:///home/iceberg/warehouse

# S3 (optionnel)
# spark.hadoop.fs.s3a.access.key=...
# spark.hadoop.fs.s3a.secret.key=...
# spark.hadoop.fs.s3a.aws.credentials.provider=...
```

---

## ðŸ”Œ Exemples dâ€™usage dans un notebook

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("Iceberg-Jupyter") \
    .getOrCreate()

# CrÃ©er une table Iceberg
spark.sql("""
CREATE TABLE IF NOT EXISTS local.db.test_table (
    id BIGINT,
    data STRING
) USING iceberg
""")

df = spark.createDataFrame([(1, "a"), (2, "b")], ["id", "data"])
df.writeTo("local.db.test_table").append()
spark.table("local.db.test_table").show()
```

---

## ðŸ› ï¸ Personnalisation

- **Changer les versions** : Ã‰ditez les `ENV` dans le `Dockerfile`.
- **Ajouter des dÃ©pendances Python** : Modifiez `requirements.txt`.
- **Ajouter des JARs** : Ajoutez des `RUN curl â€¦` avant la copie de `spark-defaults.conf`.
- **Mode cluster** : Cette image est conÃ§ue pour le **mode standalone local** (`local[*]`). Pour Spark Standalone ou Kubernetes, adaptez lâ€™entrypoint.

---

## ðŸ“ Notes importantes

- Le **serveur Spark UI** est accessible sur `http://localhost:4040` aprÃ¨s exÃ©cution dâ€™une action Spark.
- Lâ€™image **ne dÃ©marre pas Spark Master/Worker** par dÃ©faut â€” elle est centrÃ©e sur le mode *local notebook driver*.
- Pour AWS/GCP/Azure : configurez les identifiants via variables dâ€™environnement ou fichiers montÃ©s (ex: `~/.aws/credentials`).

---

## ðŸ“„ Licence

Lâ€™image hÃ©rite des licences Apache 2.0 (Spark, Iceberg, Hadoop), MIT/BSD (Python, Jupyter), etc.

---

> ðŸ’¡ **Astuce** : Utilisez cette image comme base pour vos pipelines CI/CD ou vos environnements dev/test EC2 (ex: `t3a.xlarge`), en montant vos notebooks via volumes.
```