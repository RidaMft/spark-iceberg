# ğŸ³ Docker Image : Spark + Iceberg + Jupyter Notebook

Une image Docker autonome intÃ©grant **Apache Spark**, **Apache Iceberg**, et **Jupyter Notebook**, conÃ§ue pour le dÃ©veloppement local ou en environnement cloud (AWS / Azure / GCP). IdÃ©ale pour manipuler des tables Iceberg dans des notebooks Python (PySpark), avec connectivitÃ© native vers S3, ADLS et GCS.

---

## ğŸ§° Technologies intÃ©grÃ©es

| Composant | Version |
|----------|---------|
| **Base** | `python:3.11.4-bullseye` |
| **OpenJDK** | 17 |
| **Spark** | `3.5.7` (Hadoop 3) |
| **Iceberg Runtime** | `1.10.0` (Spark 3.5 + Scala 2.12) |
| **Hadoop-AWS** | `3.3.4` |
| **AWS Java SDK** | `1.12.353` |
| **Bundles Cloud** | `iceberg-aws-bundle`, `iceberg-gcp-bundle`, `iceberg-azure-bundle` (v1.10.0) |
| **Jupyter + PySpark** | Via `spylon-kernel` et `pyspark` |
| **AWS CLI** | v2 (installÃ© globalement) |


---

## ğŸ“¦ FonctionnalitÃ©s

- âœ… ExÃ©cution interactive de notebooks PySpark avec support Iceberg (`CREATE TABLE`, `MERGE INTO`, etc.)
- âœ… Connexion native aux stockages :
  - **AWS S3** via `s3a://`
  - **Azure Data Lake** (ADLS Gen2) via `abfss://`
  - **Google Cloud Storage** via `gs://`
- âœ… PrÃ©chargement des JARs nÃ©cessaires (pas besoin de `--packages`)
- âœ… Interface Jupyter accessible sans token/mot de passe (mode dev uniquement âœ…)
- âœ… Commandes `notebook` / `pyspark-notebook` pour lancer Spark en mode driver notebook
- âœ… Dossiers montables pour notebooks, warehouse locale, etc.

---

## ğŸš€ Utilisation rapide

### Construire lâ€™image

```bash
docker build -t spark-iceberg-jupyter:latest .
```

### Lancer localement

```bash
docker run -it \
  -p 8888:8888 \
  -p 4040:4040 \
  -v $(pwd)/notebooks:/home/iceberg/notebooks \
  -v $(pwd)/warehouse:/home/iceberg/warehouse \
  spark-iceberg-jupyter:latest
```

â¡ï¸ Ouvrez [http://localhost:8888](http://localhost:8888) dans votre navigateur.

> ğŸ” **SÃ©curitÃ©** : En production, dÃ©sactivez `--NotebookApp.token=''` et ajoutez un mot de passe.

---

Voici une section **Â« ğŸ³ DÃ©ploiement sur Docker Hub Â»** Ã  ajouter Ã  votre `README.md`, compatible avec les bonnes pratiques et les contraintes de votre environnement (ex: prÃ©fÃ©rence pour les branches `dev` avant `main`, scripts automatisÃ©s, etc.) :

---

## ğŸ³ DÃ©ploiement sur Docker Hub

### 1. Construire lâ€™image avec un *tag* sÃ©mantique

```bash
# Exemple : tag de dev + date
TAG="dev-$(date +%Y%m%d)"
docker build -t <votre_dockerhub_id>/spark-iceberg-jupyter:${TAG} .

# Tag optionnel pour latest (Ã  utiliser avec prudence)
docker tag <votre_dockerhub_id>/spark-iceberg-jupyter:${TAG} <votre_dockerhub_id>/spark-iceberg-jupyter:latest
```

> ğŸ”” **Bonnes pratiques**  
> - Utilisez toujours un tag explicite (ex: `v1.2.0`, `dev-20251218`) plutÃ´t que `latest` en CI/CD.  
> - Pour les PRs ou branches de dev, prÃ©fÃ©rez `dev-<branch>-<sha>`.

---

### 2. Pousser sur Docker Hub

```bash
docker login

docker push <votre_dockerhub_id>/spark-iceberg-jupyter:${TAG}
docker push <votre_dockerhub_id>/spark-iceberg-jupyter:latest  # si nÃ©cessaire
```
---

### 3. Utilisation depuis Docker Hub

Une fois poussÃ©e, tout utilisateur peut exÃ©cuter :

```bash
docker run -it -p 8888:8888 \
  -v $(pwd)/notebooks:/home/iceberg/notebooks \
  rmeftah/spark-iceberg:3.5.7-1.10.0
```


---

## ğŸ“ Structure des dossiers

| Chemin dans le conteneur | Usage |
|--------------------------|-------|
| `/home/iceberg/notebooks` | Dossier par dÃ©faut des notebooks |
| `/home/iceberg/warehouse` | Warehouse locale (peut Ãªtre montÃ©e) |
| `/home/iceberg/localwarehouse` | Alternative pour tests locaux |
| `/home/iceberg/spark-events` | Pour le monitoring Spark UI (Ã  activer via conf) |
| `/opt/spark/conf/spark-defaults.conf` | Fichier de configuration inclus |
| `/opt/spark/jars/` | Tous les JARs Iceberg + Hadoop-AWS prÃ©installÃ©s |

---

## âš™ï¸ Configuration

Le fichier `spark-defaults.conf` est copiÃ© Ã  la construction. Exemple minimal recommandÃ© :

```properties
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
spark.sql.catalog.spark_catalog.type=hive
spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.local.type=hadoop
spark.sql.catalog.local.warehouse=file:///home/iceberg/warehouse

# S3 (optionnel)
# spark.hadoop.fs.s3a.access.key=...
# spark.hadoop.fs.s3a.secret.key=...
# spark.hadoop.fs.s3a.aws.credentials.provider=...
```

---

## ğŸ”Œ Exemples dâ€™usage dans un notebook

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("Iceberg-Jupyter") \
    .getOrCreate()

# CrÃ©er une table Iceberg
spark.sql("""
CREATE TABLE IF NOT EXISTS local.db.test_table (
    id BIGINT,
    data STRING
) USING iceberg
""")

df = spark.createDataFrame([(1, "a"), (2, "b")], ["id", "data"])
df.writeTo("local.db.test_table").append()
spark.table("local.db.test_table").show()
```

---

## ğŸ› ï¸ Personnalisation

- **Changer les versions** : Ã‰ditez les `ENV` dans le `Dockerfile`.
- **Ajouter des dÃ©pendances Python** : Modifiez `requirements.txt`.
- **Ajouter des JARs** : Ajoutez des `RUN curl â€¦` avant la copie de `spark-defaults.conf`.
- **Mode cluster** : Cette image est conÃ§ue pour le **mode standalone local** (`local[*]`). Pour Spark Standalone ou Kubernetes, adaptez lâ€™entrypoint.

---

## ğŸ“ Notes importantes

- Le **serveur Spark UI** est accessible sur `http://localhost:4040` aprÃ¨s exÃ©cution dâ€™une action Spark.
- Lâ€™image **ne dÃ©marre pas Spark Master/Worker** par dÃ©faut â€” elle est centrÃ©e sur le mode *local notebook driver*.
- Pour AWS/GCP/Azure : configurez les identifiants via variables dâ€™environnement ou fichiers montÃ©s (ex: `~/.aws/credentials`).

---

## ğŸ“„ Licence

Lâ€™image hÃ©rite des licences Apache 2.0 (Spark, Iceberg, Hadoop), MIT/BSD (Python, Jupyter), etc.

---

> ğŸ’¡ **Astuce** : Utilisez cette image comme base pour vos pipelines CI/CD ou vos environnements dev/test EC2 (ex: `t3a.xlarge`), en montant vos notebooks via volumes.
```